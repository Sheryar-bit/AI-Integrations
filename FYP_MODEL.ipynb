{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNba1E5qSREfOhOaQLui6gL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sheryar-bit/AI-Integrations/blob/main/FYP_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Oll-MecvcGi"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/diffusers.git\n",
        "!pip install -U -q transformers accelerate bitsandbytes peft datasets\n",
        "!pip install -q opencv-python-headless matplotlib\n",
        "\n",
        "!rm -rf diffusers\n",
        "!git clone https://github.com/huggingface/diffusers.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MIvYK--4vob9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Logos\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/logo_model_output\"\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "metadata": {
        "id": "PLV4xBvxxhHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import json\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(\"cuda\")\n",
        "\n",
        "metadata = []\n",
        "image_files = [f for f in os.listdir(DATASET_PATH) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "print(f\"Captioning {len(image_files)} images... this may take a few minutes.\")\n",
        "\n",
        "for filename in image_files:\n",
        "    img_path = os.path.join(DATASET_PATH, filename)\n",
        "    raw_image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "    inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\")\n",
        "    out = model.generate(**inputs)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "    full_caption = f\"{caption}, professional logo style\"\n",
        "\n",
        "    metadata.append({\"file_name\": filename, \"text\": full_caption})\n",
        "\n",
        "with open(os.path.join(DATASET_PATH, 'metadata.jsonl'), 'w') as f:\n",
        "    for entry in metadata:\n",
        "        f.write(json.dumps(entry) + \"\\n\")\n",
        "\n",
        "print(\"Metadata generated successfully!\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xdfV3JTXyMud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config default\n",
        "\n",
        "# Start Training\n",
        "!python /content/diffusers/examples/text_to_image/train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "  --train_data_dir=\"$DATASET_PATH\" \\\n",
        "  --dataloader_num_workers=2 \\\n",
        "  --resolution=512 \\\n",
        "  --center_crop \\\n",
        "  --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --max_train_steps=1500 \\\n",
        "  --learning_rate=1e-04 \\\n",
        "  --max_grad_norm=1 \\\n",
        "  --lr_scheduler=\"cosine\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --output_dir=\"$OUTPUT_DIR\" \\\n",
        "  --checkpointing_steps=500 \\\n",
        "  --validation_prompt=\"a minimalist logo for a tech company, clean lines\" \\\n",
        "  --seed=42 \\\n",
        "  --mixed_precision=\"fp16\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "P8d44BLL0xBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "# Untrained base model\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "# trained LoRA weights\n",
        "pipe.load_lora_weights(OUTPUT_DIR)\n",
        "\n",
        "prompt = \"a modern logo for a Elite Spots Brand. \"\n",
        "image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]\n",
        "\n",
        "image.save(\"generated_logo.png\")\n",
        "image"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ONwunN6M_6Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL import Image\n",
        "\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "prompt = \"a modern logo for a Elite Spots Brand\"\n",
        "seed = 42 # Using the exact same seed is the \"secret\" to a fair test\n",
        "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "\n",
        "# UNTRAINED (Base) Model\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
        "print(\"Generating image with UNTRAINED model...\")\n",
        "image_untrained = pipe(prompt, generator=generator, num_inference_steps=30).images[0]\n",
        "\n",
        "#(Trained)\n",
        "print(\"Loading your LoRA weights...\")\n",
        "pipe.load_lora_weights(OUTPUT_DIR)\n",
        "# Reset the generator so the noise starts exactly the same\n",
        "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "\n",
        "print(\"Generating image with TRAINED model...\")\n",
        "image_trained = pipe(prompt, generator=generator, num_inference_steps=30).images[0]\n",
        "\n",
        "\n",
        "comparison = Image.new('RGB', (1024, 512))\n",
        "comparison.paste(image_untrained, (0, 0))\n",
        "comparison.paste(image_trained, (512, 0))\n",
        "\n",
        "print(\"Left: Untrained (Base SD 1.5) | Right: Your Trained Logo Model\")\n",
        "comparison.save(\"comparison_result.png\")\n",
        "display(comparison)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IEGttgmeBR8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.set_adapters([\"default\"], adapter_weights=[0.6])\n",
        "\n",
        "prompt = \"professional logo style, minimalist mountain, vector art\"\n",
        "image = pipe(prompt, num_inference_steps=30, guidance_scale=7.0).images[0]\n",
        "display(image)"
      ],
      "metadata": {
        "id": "SrPUQUMOL9dk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}